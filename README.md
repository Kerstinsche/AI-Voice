# personal AI-Voice
Final project for the Building AI course
## Summary
If you find yourself in the situation of losing your voice and you need to use a voice computer, it should be possible for you to get your own voice back digitally. Without having to rely on the specifications of individual devices.
## Background
When people lose their voice after a drastic experience (e.g. accident or sickness) or due to physical limitations and then have to rely on a speech computer, it gives them back a great deal of independence, but does not complete their identity in a whole. 
Speech is an unmistakable feature of our identity due to the anatomy of our speech organs. If this is missing, many patients struggle with the rather monotonous computer voice with which a speech computer expresses their wishes. As the voices of well-known personalities are either subject to personal rights or the standard voices are used by too many people with or without handicap, this does not necessarily create an identity either.
With the support of e.g. auditory AI “MAL” (see also Beatles “Now and Then”, release 2023) older audio recordings of patients could be used as the basis for auditory speech recognition. Coupled with emotional speech synthesis, patients could be given back a large part of their language identity and their quality of life could be improved.
## How is it used?
Old sound recordings are first digitized if they are still analogue.
The speech sequences obtained in this way are implemented as the output language for the speech computer.
As an add-on, if not already stored in the system, a program for emotional speech synthesis is added.
Both the output language and emotionality must be adjustable with a slider or button for selection in order to lend emphasis or indifference to a corresponding statement.
## Data sources and AI methods
- own voice recordings
- existing voice AI (standard voice recordings of the corresponding voice computer)
- Emotional speech synthesis AI (see example link below)
## Challenges
The older the patient is when they lose their voice and the less source material (voice recordings) they have, the more difficult it is to mechanically approximate the original voice. The psychological level must not be ignored here either, as even minimal deviations from the familiar can trigger identity disorders. Even if these should be smaller in comparison to the unprocessed voice computer material.
## What next?
Since there are still people who lose their voice due to external circumstances, but on the other hand there are currently non-personalized voice computers, it is necessary to do appropriate lobbying work. The main headwind will come from health insurance companies, who fear a large additional financial burden for their policyholders. 
However, the rapid pace of technical development means that the cost pressure is likely to be limited. In addition, an improvement in the quality of life and therefore less psychological support over the course of a lifetime will have an impact. 
It is also possible that companies in the audio sector will specialize in this niche or that the technology will be available to every recording studio.
## Acknowledgments
Martin Pistorius „Ghost Body“, Simon & Schuster UK Ldt., 2011 (German version: „Als ich unsichtbar war“ Bastei Lübbe GmbH & Co KG, 2012)

[„Now and Then“: Die Beatles vereint durch KI] https://www.gema.de/de/w/neuer-beatles-song-durch-ki (02 April 2024)

[ESPESY: Entwicklung einer emotionalen Sprachassistenz] https://www.wesound.de/de/espesy-emotionale-sprachassistenz/ (01 Feb 2021)
